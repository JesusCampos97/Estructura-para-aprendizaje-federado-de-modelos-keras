** Se guarda información de lo que va pasando a modo de historial **

*- 30/04/22 -*
    Se ha generado un modelo con menos parametros que aparentemente funciona bien. Se tiene que comprobar le mergeo y el accuracy
    D0 -> acc 0.8821 y val_acc 0.9633 - loss 0.2977 y val_loss 0.2373
    D1 -> acc 0.8918 y val_acc 0.8991 - loss 0.2974 y val_loss 0.22
    MERGED evaluate by d0 -> acc 0.9183 y loss 0.4444
    MERGED evaluate by d1 -> acc 0.9060 y val_acc 0.45 

*- 01/05/22 -*
    Se crea la parte de reentrenaimiento y se comprueba con 2 modelos y 2 días reentrenando. Se arregla el plot y se comprueba
    * Día-1
        D0 -> acc 0.8821 y val_acc 0.9633 - loss 0.2977 y val_loss 0.2373
        D1 -> acc 0.8918 y val_acc 0.8991 - loss 0.2974 y val_loss 0.22
        MERGED evaluate by d0 -> acc 0.9183 y loss 0.4444
        MERGED evaluate by d1 -> acc 0.9060 y val_acc 0.45 

    Cascazo

*- 02/05/22 -*
    Se generan reusltados en csv y se hecha a andar con 2 devices y 2 días de reentreno pero con una sola época para comprobar si e smejor 1 epoc ay más días con el merge
    Habría que comprobar si, 2 epocas y 2 días >= a 1 epoca y 4 días y qu edarnso con ese resultado

*- 08/05/22 -* 
    Se generan todas las tablas bien y tenemos muy buenos resultados con el modelo VGG16 en el '08-05-2022 16-13'. Todos mejoran. aprox 2h de ejecucion con 2 devices y 4 days
    Generamos lo mismo con el model MobileNetV2

*- 11/05/22 -*
    Hay que agregar un dispositivo entrenado bien que sea el pilar del que aprenden todos de inciio  yprobar que tal va. Por ahora no hay malos resultados parece ser
    Hay que dejar el mobilenet el mismo tiempo que tarda el vgg16 (unas 6h) y ver como funciona.
    Se deja ejecutando vgg16 5devices, 5 días para comprovar resultados
    /home/pi/Desktop/proyecto/Estructura-para-aprendizaje-federado-de-modelos-keras/Devices/5/11-05-2022 13-37 -> dense de 1024 -> buenos resultados
    /home/pi/Desktop/proyecto/Estructura-para-aprendizaje-federado-de-modelos-keras/Devices/5/11-05-2022 17-23 -> dense de 512 -> esta bien tambien, da igual

    *Probar que Mobilenetv2 con 1024 y 512
    *Probar un modelo muy bueno como referencia-> 0.9 acc -> 1/11/05/22 23-24 y 0.85 acc-> 1/11-05-22 23-24
    *Probar el tiempo dle VGG16 en 5 días y 5 devices
    *Probar el MobileNet 10 y 15 días y 5 devices
    *Probar el MobileNEt 5,10,15 días y 10,15 devices
    *Probar el vgg16 con 10 y 15 días 5 y 10 devices

*- 12/05/22 -*
    Se prueba el mejor modelo de 0.9 de acc para empezar con el-> validations no mejores y trains no mejores, aprox iguales, se prueban otras cosas a ver que tal->5/12-05-22 10-15
    Se prueba el mejor modelo de 0.9 como pilar de merge
    Se prueba el mejor modelo de 0.9 como comienzo y pilar de merge-> resultados del train un pelin mejores y val igual aunque val_loss raro -> 5/12-05-22 15-28

    Se prueba el mejor modelo de 0.85 de acc para empezar con el-> 5/12-05-22 18-32 -> es aprox igual que el de 0.9 misma grafica casi. Al saber eso se prueba que
    pasa con más devices (10 y 15)
    Se prueba el mejor modelo de 0.85 como pilar de merge
    Se prueba el mejor modelo de 0.85 como comienzo y pilar de merge

    coger lo mejor y dejarlo en 10, 15 días con  devices
    dejarlo 5,10,15 dias para 10 devices

    Se prueba el modelo con 10 devices, merge y pilar de 0.85 y tenemos graficas de train y loss mejores, leves, pero mejorando. 
        las graficas de val salen raras peor mejoran al final->10/12-05-22 21-25
    Se prueba el modelo con 5 devices durante 10 días con pilar y merge y se comprueba si mejora-> datos bastante buenos... mejora accuracy y loss en general
    Lo de arriba deberia de ser similar??  hay diferencia

*- 13/05/22 -*
    Se prueba un tamaño del lote de 10 a ver si no casca por memoria...
    Probar 5 devices 10 dias y comparar.. y ver si no peta.
    Si va mejor, ejecutamos con 10 devices y 5 días y vemos si no peta etc


*- 14/05/22 -*
    Se prueba un batch size de 32
    Se quiere probar que los datasets tengan las clases igualdas, cogiendo 80% de positivos y negativos (clases) y que así el val accuracy luego no se ponga tan loco
    Si con esto ultimo el val sigue oscilando tanto, es debido a que hay sobreajuste y hay que realizar algo para tener más imagenes en el dataset
    Mergear solo los modelos con un val accuracy superior a un umbral como diciendo que este modelo no tiene sobreajuste.
    Hay que probar si quitando el pilar de merge mantiene los resultados

*- 16/05/22 -*
    Se crea con dropout server_model_dropout.h5
    Hay que probar con la mediana
    
*- 17/05/22 -*
    Se prueba la mediana y el dropout
    Se deja ejecutando con mediana 5 dispositivos 10 días
    Se deja ejecutando con mediana 5 dispositivos 5 días si el anterior va bien para ver si hay diferencia.

*- 22/05/22 -*
    5 dispositivos -> 15 días -> /5/22-05-2022 22-11
    Se prueba con otro tpo de merge con 5 device sy 5 días (ponderedAverage)

*- 24/05/22 -*
    la media ponderada se prueba con 5 devices y 5 días. No parece que funcione muy bien. -> /5/24-05-2022 10-54
    se mira los layers entrenables->ok
    Se prueba el ensamble4 con el average normal-> va mal por lo que es el ensamble que tengo
    se vuwelve a prpobar un con un cambio el pondered co el ensemble normal
    se purueba el decreasing exponential

*- 25/05/22 -*
    10/25-05-2022 00-03 -> usa merge de tipo 2 -> 10 devices y 15 días

*- 26/05/22 -*
    10/26-05-2022 09-19 -> usa merge de tipo 3 -> 10 devices y 15 días

*- 27-05-22 -*
    10/27-05-2022 10-25 -> usa merge de tipo 1 -> 10 devices y 15 días

*- 28-05-22 -*
    Se ejecuta un VGG16 para 1 devices 5 epocas para ejecutarlo en federADO POSTERIORMENTE-> bad aloc
    sE NECESITA METER EL TIPO 1 CON 20 DEVICES
    Se meten nuevas imagenes y se ejecuta:
    5/28-05-2022 -> merge tipo 1 -> 5 devices 5 días de pruebas con mas imagenes 

*- 31-05-22 -*
    5/30-05-2022 12-40 -> merge tipo 1 -> 5 devices 20 días con imagenes reducidas en cantdad. Terminado va flama
    20/02-06-2022 09-09 -> va muy bien-> merge 1
    10/31-05-2022 13-17 -> merge tipo 1-> va bien

*- 05/06/22 -*
    5/05-06-2022 13-06 -> merge tipo 3 -> 5d 20d